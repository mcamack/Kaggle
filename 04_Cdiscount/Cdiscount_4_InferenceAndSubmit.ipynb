{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/title.png\" alt=\"Drawing\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This competition aims to correctly classify millions of products for e-commerce company Cdiscount.com. Perform image classification for each of the 9 million products into 1 of 5000 categories, with each product having 1-4 images (180x180 resolution) in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "* category_names.7z\n",
    " * Shows hierarchy of product classification\n",
    " * Each category_id has a level1, level2, level3 name in French\n",
    " * each Product's category_id corresponds to a specific level 1, 2, and 3 level (specific spot in the category tree)\n",
    "* train_example.bson\n",
    " * First 100 dicts from train.bson\n",
    "* train.bson\n",
    " * List of 7,069,896 dictionaries (one per product) with keys:\n",
    " * product id ( **\\_id: 42** )\n",
    " * category id ( **category_id: 1000021794** )\n",
    " * list of 1-4 images in a dictionary ( **imgs: [{'picture':b'...binarystring...'}, {'picture':b'...binarystring...'}]** )\n",
    "* test.bson\n",
    " * List of 1,768,182 products in same format as train.bson, except there is no 'category_id' with each image\n",
    "* sample_submission.7z \n",
    "\n",
    "\n",
    " | \\_id   | category_id   |  \n",
    " |:---    |:---           |\n",
    " | 10     |\t1000010653    |\n",
    " | 14     |\t1000010653    |\n",
    " | 21     |\t1000010653    |\n",
    " | 24     |\t1000010653    |\n",
    " | 27     |\t1000010653    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.data import imread\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def slack(message):\n",
    "    webhook_url = 'https://hooks.slack.com/services/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'\n",
    "    slack_data = {'text': message, \"link_names\":1}\n",
    "\n",
    "    response = requests.post(\n",
    "        webhook_url, data=json.dumps(slack_data),\n",
    "        headers={'Content-Type': 'application/json'})\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Submission Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This will be the directory we pull images from, all images must be in subdirs of this path (even if only 1 folder)\n",
    "testrepo = \"C:\\\\Kaggle\\\\04_Cdiscount\\\\\"\n",
    "datarepo = \"D:\\\\Kaggle\\\\04_Cdiscount\\\\\"\n",
    "\n",
    "#The batch size to use for NN\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build VGG16 Model\n",
    "Construct a VGG16 model in Keras which will accept the images from this competition as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean   #subtract mean\n",
    "    return x[:, ::-1]  #RGB -> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Conv2D(filters, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), data_format=\"channels_first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FullyConnectedBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "    \n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    FullyConnectedBlock(model)\n",
    "    FullyConnectedBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model and Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model.pop()\n",
    "model.add(Dense(5270, activation='softmax'))\n",
    "model.load_weights(datarepo + \"weights\\\\finetune_best_weights2.hdf5\")\n",
    "model.compile(optimizer=RMSprop(lr=0.000005), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Master List of Images\n",
    "Create_Image_List allows us to feed our custom generator with a customized image list. Each image can be grabbed once, or we can grab the same number of images from each training class regardless of it's actual size. This will loop back to the beginning for smaller classes and help the imbalanced dataset problem. The list can be shuffled or given sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def Create_Image_List(directory, perclass=0, seed=42, shuffle=False):\n",
    "    \"\"\"\n",
    "    Return a list of images \n",
    "    Directory must contain subdirs which are the class names\n",
    "    Shuffle will randomize how images are selected from the subdir\n",
    "    perclass amount of images will be pulled from each subdir (looping if needed)\n",
    "    1st output image is from 1st subdir class, 2nd from 2nd class, etc ... looping back to 1st class\n",
    "    \"\"\"\n",
    "    Lfiles = []\n",
    "    Lclasses = []\n",
    "    Lmaster = []\n",
    "\n",
    "    for i,(dirpath, dirname, fname) in enumerate(os.walk(directory)):\n",
    "        if i == 0:\n",
    "            Lclasses = dirname\n",
    "        else:\n",
    "            Lfiles.append([Lclasses[i-1], fname])\n",
    "    \n",
    "    #count total images\n",
    "    totalimgs = 0\n",
    "    for item in Lfiles:\n",
    "        totalimgs += len(item[1])    \n",
    "\n",
    "    print(\"Found\", str(len(Lfiles)), \"classes with a total of\", totalimgs, \"images\" )\n",
    "\n",
    "    #shuffle each classes' image list\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "        for i,tmp in enumerate(Lfiles):\n",
    "            random.shuffle(Lfiles[i][1])\n",
    "\n",
    "    #create an output list with each image appearing once\n",
    "    if perclass == 0:\n",
    "        for cls in Lfiles:\n",
    "            for img in cls[1]:\n",
    "                Lmaster.append(cls[0] + \"\\\\\" + img)\n",
    "    \n",
    "    #create the output list of images\n",
    "    #if perclass is greater than num of images in a class, loop back to it's first img\n",
    "    #every class will have same num of images\n",
    "    if perclass > 0:\n",
    "        for idx in range(perclass):\n",
    "            for cls in Lfiles:\n",
    "                looper = idx % len(cls[1])\n",
    "                Lmaster.append(cls[0] + \"\\\\\" + cls[1][looper])\n",
    "    \n",
    "    if perclass == 0:\n",
    "        print(\"Returning a list with all images in each class, totaling\", str(len(Lmaster)), \"images\")\n",
    "    else:\n",
    "        print(\"Returning a list with\", str(perclass), \"images per class, totaling\", str(len(Lmaster)), \"images\")\n",
    "    \n",
    "    return Lmaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 classes with a total of 3095080 images\n",
      "Returning a list with all images in each class, totaling 3095080 images\n"
     ]
    }
   ],
   "source": [
    "Master_Images_Test = Create_Image_List(directory=testrepo, perclass=0, seed=42, shuffle=False)\n",
    "Master_Filenames = [i.split('\\\\')[1] for i in Master_Images_Test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Master List of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = pd.read_csv(r'D:\\Kaggle\\04_Cdiscount\\category_names.csv', index_col='category_id')\n",
    "Master_Classes = categories.index.tolist()\n",
    "Master_Classes.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Generator\n",
    "This will endlessly feed images to the predict stage. This is more configurable than the normal Keras image data generator and works better on this system for some reason. Keras' IDG was skipping batches and giving erroneous results. The helper function *Open_Image* is useful so the generator will yield correctly formatted images. They must be numpy arrays of size 224x224 with \"channels first\" aka (3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Open_Image(directory, path):\n",
    "    im = Image.open(directory + path)\n",
    "    imarray = np.array(im)\n",
    "    imresize = misc.imresize(imarray, (224,224)) \n",
    "    imT = np.transpose(imresize, (2,0,1)) \n",
    "    #img = Image.fromarray(imarray, 'RGB')\n",
    "    #img.show()\n",
    "    return imT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Batch_Generator(dataset, batch_size, repo):\n",
    "    for i in range(0,len(dataset), batch_size):\n",
    "        batch = dataset[i : i+batch_size]\n",
    "        yield np.asarray([Open_Image(repo, i) for i in batch]),np.asarray([i.split('\\\\')[0] for i in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batches = Batch_Generator(dataset=Master_Images_Test, batch_size=batch_size, repo=testrepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Output Classes for Submission Test Set\n",
    "It may be worth looking at predictions for each image of a product (up to 4) and combining results or voting in order to determine best classification. Possibly run the extra images through a different NN then ensemble?\n",
    "\n",
    "The prediction output contains 5,270 columns per sample, so we must predict in batches, saving predicted output classes in an array along the way. We run out of memory if we try to predict all the submission test images at once (millions of images x 5,270 values/image x 4 bytes/value = WAY TOO BIG FOR MEMORY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master_Classifications = []\n",
    "\n",
    "# for i,(imgs,labels) in enumerate(test_batches):\n",
    "#     if i%100 == 0: print(\"Finished batch:\", str(i), \"/96721\")\n",
    "#     preds = model.predict_on_batch(imgs)\n",
    "#     highest_prob = np.argmax(preds, axis=1)\n",
    "#     for highest in range(len(highest_prob)):\n",
    "#         idx = highest_prob[highest]\n",
    "#         Master_Classifications.append(Master_Classes[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  293/96721 [..............................] - ETA: 23431s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0f5357e4da8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m preds = model.predict_generator(generator=test_batches, steps=(len(Master_Images_Test)//batch_size),\n\u001b[1;32m----> 4\u001b[1;33m                                max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhighest_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1200\u001b[0m                                             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m                                             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m                                             verbose=verbose)\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   2292\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2294\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2296\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1827\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1830\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2255\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2256\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2257\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\matt\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Master_Classifications = []\n",
    "\n",
    "preds = model.predict_generator(generator=test_batches, steps=(len(Master_Images_Test)//batch_size),\n",
    "                               max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n",
    "\n",
    "highest_prob = np.argmax(preds, axis=1)\n",
    "for highest in range(len(highest_prob)):\n",
    "    idx = highest_prob[highest]\n",
    "    Master_Classifications.append(Master_Classes[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slack(\"FINISHED CLASSIFICATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Predictions into Submission Format\n",
    "- Create a numpy array with a header of 2 columns named **_id** and **category_id**\n",
    "- Each row should be in the format of **_id,category_id** such as **5,1000016018**\n",
    " - Strip off the \"-#.png\" portion of each filename\n",
    " - use class_list to find the category_id\n",
    "- Only parse out preds and filenames for images ending in \"-1.png\"\n",
    "- **MAKE SURE FINAL SUBMISSION HAS 1,768,182 ROWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the \".jpg\" extension\n",
    "parsed_filenames = []\n",
    "for imgname in Master_Filenames:\n",
    "    parsed_filenames.append(imgname.split('.')[0])\n",
    "\n",
    "#combine filenames and classifications into 1 numpy array\n",
    "a = np.array(parsed_filenames)\n",
    "b = np.array(Master_Classifications)\n",
    "submission_array = np.column_stack((a,b))\n",
    "\n",
    "#turn the numpy array into a Pandas Dataframe\n",
    "df = pd.DataFrame(data=submission_array)\n",
    "df.columns = ['_id', 'category_id']\n",
    "df = df[df._id.str.contains('-1')]\n",
    "df['_id'] = df['_id'].str[:-2]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.shape != (1768182, 2):\n",
    "    print(\"Error: final submission dataframe shape should be (1768182, 2) but got\", df.shape,\"instead\")\n",
    "else:\n",
    "    print(\"Ready for submission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Zip file for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "\n",
    "output_file = \"final_submission6\"\n",
    "\n",
    "df.to_csv(datarepo + \"submissions\" + \"\\\\\" + output_file + \".csv\", index=False)\n",
    "os.chdir(datarepo + \"submissions\")\n",
    "ZipFile(output_file + \".zip\", \"w\", ZIP_DEFLATED).write(output_file + \".csv\")\n",
    "\n",
    "print(datarepo + \"submissions\" + \"\\\\\" + output_file + \".csv ready for submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
